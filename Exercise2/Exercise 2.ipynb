{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 Gradient Descent, Linear Regression and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this who take numerical method already. The first half is sort of recap.\n",
    "\n",
    "1) Where is the minimum for\n",
    "\n",
    "$$f(x, y) = (x-2)^2 + (y-3)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "x = 2,\n",
    "y = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) After this class and for the rest of your life(except for exam) use library like this unless the library doesn't do exactly what you want(which is rare)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(xs):\n",
    "    x, y = xs #this is called variable unpacking. USE it to make your code look nicer\n",
    "    return (x-2)**2 + (y-3)**2\n",
    "\n",
    "f([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 63\n",
      "         Function evaluations: 123\n"
     ]
    }
   ],
   "source": [
    "import scipy.optimize as opt\n",
    "opt.fmin(f, [0,1])\n",
    "# ?opt.fmin #bring up documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Now let us understand the magic behind it. For $f(x,y)$ given above find the gradient at (1,2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$\\nabla f(x, y) = 2(x-2)\\hat{x} + 2(y-3) \\hat{y}$$\n",
    "$$\\nabla f(1,2) = -2\\hat{x} -2\\hat{y}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Find the unit vector that has the same direction as the gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$ \\frac{\\nabla f}{|\\nabla f|} = \\frac{-1}{\\sqrt{2}} \\times (\\hat{x} + \\hat{y}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Which direction should we walk?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$ \\frac{1}{\\sqrt{2}} \\times (\\hat{x} + \\hat{y}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) How far should we walk? What is wrong with large step size and what is wrong with small step size?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<span style=\"color:red\">Large step size -> Stepping over the minimum\n",
    "<br/>Small step size -> Takes forever</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Where do we want large step size and where do we want small step size?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<span style=\"color:red\">Far away from minimum -> Large step\n",
    "<br/>Small step size -> Takes forever</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Given that we don't really know where the minimum is. How do we get a qunatity what has such behavior?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) What is a learning rate? What is wrong with large learning rate and what is wrong with small learning rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) Write down the \"update rule\"\n",
    "\n",
    "$$\\vec{x}_{i+1} = \\vec{x}_{i} + \\ldots $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11) Given our update and learning rate of 0.01 rule compute the next guess ($\\vec{x}_{1}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12) Compute ($\\vec{x}_2$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13) Compute ($\\vec{x}_{100}$). Of course, don't do it by hands you have a computer for a reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.99995898  2.99995898]\n"
     ]
    }
   ],
   "source": [
    "xs = np.array([1, 2])\n",
    "def f(xs):\n",
    "    x, y = xs #this is called variable unpacking. USE it to make your code look nicer\n",
    "    return (x-2)**2 + (y-3)**2\n",
    "def df(xs):\n",
    "    x, y = xs\n",
    "#     return np.array([2*(x-2), 2*(y-3)])\n",
    "    h = 1e-10\n",
    "    dx = ( f(xs + np.array([h, 0])) - f(xs) ) / h\n",
    "    dy = ( f(xs + np.array([0, h])) - f(xs) ) / h\n",
    "    return np.array([dx, dy])\n",
    "eta = 0.01\n",
    "for i in xrange(500):\n",
    "    xs = xs - eta*df(xs)\n",
    "\n",
    "print xs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Previous example relies on analytical gradient which is not always available for us.\n",
    "\n",
    "How do we compute gradient numerically? (If you recall, there are at least 2 methods. Do you remember what's the difference between the two?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Find $\\vec{x}_{100}$ by using numerical gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "1) Given a bunch of data. What is the difference between good hypothesis and bad hypothesis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "2) What parametrize each hypothesis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "3) What is padded feature? Write down the cost function with padded features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "4) What the variable we are trying to adjust?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) What does $w_0$ represent and what does $w_1$ represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "6) Fit this data. (use fmin if you want)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "n = 20\n",
    "xs = np.linspace(1,3, n)\n",
    "ys = 3*xs + 2 + np.random.randn(n)*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.193620\n",
      "         Iterations: 72\n",
      "         Function evaluations: 137\n",
      "[ 2.05776679  2.98676089]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1087c2750>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAEACAYAAABBDJb9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHURJREFUeJzt3Xd0FPX+//EniCgBpEqTJiBVQCAgPWu7YkFFaV4EBTEI\ntvs7XhW8cFOAhBiQKIh0FBGkY7kg4ld3kxASCL2FUETpiCShpu/vjw0YYyDJlszu5vU4JyeT2cnM\n+wzDK7Of/Xw+AyIiIiIiIiIiIiIiIiIiIiIiIiIixWY+cAbYnWtdOLAf2AmsAioZUJeIiBRBD6Ad\nfw3zR4DSOcuTcr5ERMRApQt4PQpIyrNuA5CdsxwH1HV2USIiUjQFhXlBhgFrnVGIiIjYz5Ew/w+Q\nDix2Ui0iImKnMnb+3kvA48BDN9qgcePG1sOHD9u5exGREusw0KSov2TPnXkv4B3gaSD1htUcPozV\natWXk74CAgIMr8FbvnQudT7d+QtobEcuFxjmS4AYoBlwDFsb+TSgArYPQrcDM+w5sIiIOE9BzSzP\n57NuvisKERER+znam0WKiclkMroEr6Fz6Vw6n+6hlAv3bc1p/xERkUIqVaoU2JHNujMXEfECCnMR\nES+gMBcR8QIKcxERL6AwFxHxAgpzEREvoDAXEfECCnMRES+gMBcR8QIKcxERL6AwFxHxAgpzEREv\noDAXEfECCnMRES+gMBcR8QIKcxERL6AwFxHxAgWF+XzgDLA717p+wF4gC2jvorpERKQICgrzBUCv\nPOt2A32ASJdUJCIiRVamgNejgIZ51iW4phQREbFXQWEuIiLFICMrg0W7Ftn9+wpzEREDZWRl8MWu\nL5gQOYGGlRvavR+XhnlgYOD1ZZPJhMlkcuXhREQ8RkZWBgt3LmTs/LGUO1EOvwZ+7IpqAPxs1/4c\nDfNSN3sxd5iLiAikZ6Xz+Y7PCYkOoUnVJix/dznd63cHwHa/G2TXfgsK8yWAH1AdOAYEAOeBaTnr\n/gdsBx6z6+giIiVEelY6n+34jJCoEJpWa8qiPovoVr/bX7bx8bF//ze9s3aQ1Wq1unD3IiLuwd8f\nEhNtYbx4MVSu/Odr6VnpLNi+gNDoUJpVb0aAXwBd63XNdz/JyVClSimwI5v1AaiIiIMSE8FisS37\n+8OyZZCWmcaCHbYQb1G9BUueW0KXel1uup/cfwSKSmEuIuKga80jvr4wbUYan26ZT2h0KK1qtGJp\n36V0rtvZ5TWomUVExEHJyfDyiDS6jJrHR9tCaVOzDf/t+V/ur3t/kfdVqpSaWUREil1qZipfJs5j\nc+dJpJ1oy8r+K+l0V6dir0NhLiJih9TMVOZum8uk6Em0q92OVf1X0fGujobVozAXESmC1MxU5myd\nQ9jGMNrXbs+agWvwreNrdFkKcxGRwriacZU522wh7lvHl68Hfk2HOh2MLus6hbmIyE1czbjKrK2z\nCI8Jp2Odjnz7/Le0r+1+j3JQmIuI5ONKxhVmxdtC/P669/Pd89/RrnY7o8u6IYW5iEguVzKuMDN+\nJuEx4XSp24W1g9ZyX637jC6rQApzERHgcvplZsbPZPKmyXSt15XvB31P21ptjS6r0BTmIlKiXU6/\nzKfxnzI5ZjLd63dn/QvraVOzjdFlFZnCXERKpMvpl5mxZQZTNk2hR4MebBi8gdY1Wxtdlt00nF9E\nSpRL6Zeuh7ipoYmsn8Zxbt+9+c54aAR7h/OXdn4pIiLu51L6JcKiw2j8cWO2ndrGT0N+YmnfpZzb\ndy8WC6xbZ5vx0FOpmUVEvNrFtItM3zydiLgIHrz7QX5+8Wda3tny+uu5ZzycPdugIp1AzSwi4pUu\npF2whXhsBA83ephxPcfR4s4Wf9suOdl2Rz57tvFNLGB/M4vCXES8yoW0C0yLm8ZHcR/xj8b/YGzP\nsTSv3tzosgpNU+CKSImWkprCtM22EO/VpBdRQ6NoVr2Z0WUVm4I+AJ0PnAF251pXFdgAJAI/AG7w\nxkRESqqU1BTGW8bTZFoTEv9IZOOwjXzR54sSFeRQcJgvAHrlWTcaW5g3Bf4v52cRkWKVnJpMsCWY\nJtOacCjpEBuHbWRhn4U0rdbU6NIMUZh2mYbAt8C13vQJgB+2O/ZagBnIr0FKbeYi4nTJqclExEYw\nffN0nmz6JP/p8R/uqXaP0WU5TXG2mdfEFuTkfK9pxz5ERIok6WoSEbERfLLlE3o3603s8FiaVG1i\ndFluw9EPQK05X/kKDAy8vmwymTCZTA4eTkRKmqSrSUyNncqMLTN4qtlTxA2Po3HVxkaX5TRmsxmz\n2ezwfuxtZjEBp4HawM+omUVEnOz81fNM3TSVT+M/5Znmz/B+j/dpVKWR0WW5XHEO5/8GeDFn+UVg\njR37EBHJ1x9X/mDsT2NpOq0ppy+dZssrW5j71NwSEeSOKKiZZQm2DzurA8eA/wKTgGXAy8BRoL8L\n6xOREuKPK3/w4aYPmbl1Js+1eI54/3gaVm5odFkeQyNARaRY+ftDYiLXZynMLHuODzd9yKyts+jb\noi9jeowpVIjn3Y87DMV3Bo0AFRGPkJgIFgvgc44uY6dwtv5s+rXsxzb/bTSo3KDo+8EW7MuWuaZe\nT6EwF5Fidcsdv8PDU7il0xy6dOhP4EPbqV+pfpH34y2zHTqLmllEpFicvXyWyTGTmbttHlVPDmD1\n26NpXb/oIX6Nu8126CyaNVFE3NLZy2cJ3xjOvO3zeP7e5xndfTT1KtUzuiy3pTZzEXErZy6dITwm\nnPnb5/PP1v9k18hd1L2jrtFleS2FuYg41elLpwnfGM6CHQsY1HqQQryYKMxFxClOXzrNBxs/4LMd\nnzG4zWD2jNpDnYp1jC6rxFCYi0ih5de3+9TFU4RtDGPhzoUMaTtEIW4QhbmIFFruvt2DR52k0eAw\nvtj1BS+2fZG9o/ZSu2JtYwsswRTmIlJoPj5AxRPUeDaM6OaLuKf0S+x7bR+1KtQyurQST2EuIoVy\n4sIJ6vpP4tYOX9Kv41DGPqgQdycKcxG5qeMXjjMpehKLdy9mWLthHHtvPzUr6Jk07kZhLiL5OpZy\njEnRk1iyZwnD2w8n4fUEapSvYXRZcgMKcxH5i2MpxwiNDuWrPV/xSvtXFOIeQmEuIgD8lvIboVGh\nLNu3jFfav8KB1w9wZ/k7jS5LCklhLlLC/Zr8K6HRoSzftxz/9v4ceP0A1X2qG12WFJHCXKSEOpp8\nlJCoEFbuX8mIDiMU4h5OYS5SwvyS9AshUSGsSljFqx1eJfH1RKr5VDO6LHGQwlykhPgl6RcmRk1k\ndcJqRvqOVIh7GUfC/C1gOLZ5d+cAHzmlIhFxqiNJR3gsdCJHbv2aBr+PJD74IHfXqmp0WeJk9ob5\nvdiCvCOQAXwPfAccdlJdIuKgw+cPMzFqIt8c+Ibyv48ic2kih69W5b1kPS/TG5W28/eaA3FAKpAF\nWIBnnVWUiNjv0PlDDP16KPfPvZ/6lepz8I2DtDoTDFer6nmZXszeMN8D9ACqAj7AE4Bmnxcx0ME/\nDvLSmpfoMq8LDSs15NCbhwg0BVKlXBUWL4Z+/WDDBu96Xqb8yd5mlgQgDPgBuAxsB7LzbhQYGHh9\n2WQyYTKZ7DyciNxI4h+JTIicwLpD63ij0xscfOMglW//a2JXrqymFXdlNpsxm80O78dZD3QOAX4D\nZuZapwc6i7jQgXMHmBA1ge8Pfc+bnd7kzfvfpNLtlYwuSxxk7wOdHQnzGsBZoD6wHrgfuJDrdYW5\niAsknEtgQuQE1h9ez1v3v8Ubnd5QiHsRe8Pcka6JK4Bq2HqzjOKvQS4iTpZwLoHxkePZcHgD/+r8\nL2Y8MYM7brvD6LLETTirmSU/ujMXcYJ+o/YTyXiSq/7Ie37/j3d6vk7F2yoaXZa4iL135vb2ZhER\nF9t7di8DVwzk6yp+nN3dhvTwwyTMGaMgl3wpzEXczN6zexmwYgAPLnyQdrXaYdp5BKJH49umovqI\nyw2pmUXETew5u4dgSzCWXy283eVtRnUcRYWyFUhOBn9/22Af9RH3fkb0ZimIwlykEHaf2U1wZDBR\nv0bxdpe3GdlxJBXKVjC6LDGIwlzEw+w6s4tgSzDRv0Xz767/ZqTvSMqXLW90WWIwhbmIh9h5eifB\nkcHEHIvhna7v8Krvq/jc6mN0WeImFOYibm7H6R0EW4LZdHwT73Z9lxG+IxTi8jcKcxE3tf3UdoIj\ng4k7Hse73d7Fv4O/QlxuyIgRoCJyE9tPbSfIEsTmE5t5r9t7LH52MeVuLWd0WeKlFOYiTrb15FaC\nI4OJPxnPu13fZclzSxTi4nJqZhFxkviT8QRZgth2ahuju41mePvhCnEpMjWziBhky4ktBFmC2HF6\nB6O7j2Z5v+XcXuZ2o8uSEkZhLmKnzSc2E2QJYteZXYzuNpoV/VcoxMUwCnORIoo7HkeQJYjdZ3cz\npvsYVvVfxW1lbvvbdv7+kJgIPj6weLGG4otrKcxFCin2eCxBliD2nt3LmO5jWD1gdb4hfk1iIlgs\ntmV/fz22TVxLYS6SR9476v0XNxFoCSThXAJjuo9hzYA1Nw3xa3xyupL7+qLZDsXl1JtFJA+TKeeO\nul4MNQcEcttdB3i/+/u8dN9LhQrxazTbodhDI0BFnKRz/2jibg+ibO2DhD35PqO6vkTZW8oaXZaU\nEApzEQdF/RpFkCWIg38c5s6E91kb8iI1qinEpXgZ0c98DPACkA3sBoYCaQ7sT8QQkb9GEmQJ4kjS\nEcb2GMuQtkO49ZZbjS5LpEjsvTNvCPwEtMAW4EuBtcDnubbRnbm4NctRC0GWII4mH2Vsz7EMbjNY\nIS6GK+478wtABuADZOV8P2HnvkSKlfmomSBLEL+l/MbYHmN5oc0LCnHxePaG+XlgCvAbcBVYD/zo\nrKJEXMF81EygOZDjF44ztudYBrUepBAXr2FvmDcG/oWtuSUFWA4MAr7MvVFgYOD1ZZPJhMlksvNw\nIoWTt494pUpWfj76M0GWIE5ePMm4nuP4Z+t/Uqa0hliIezCbzZjNZof3Y2+b+QDgEWB4zs+Dgc7A\na7m2UZu5FLvrfcSx0vOln7D2DOL0pdOM6zmO51s/rxAXt1fcbeYJwDigHJAKPAxstnNfIk5TzscK\njf6PCk8EcbLxWQI6jGPgvQMV4uL17L3CdwILgXhsXRO3ARqwLIaxWq38eORHkp4JouLRc0x+ahwv\ndxrILaVvMbo0kWKhQUPi0axWKxuObCDQHEhSahLjeo5jQKsBCnHxWHo4hZQoVquVHw7/QKAlkJTU\nFMb1HEf/Vv0V4lJiKczFo1itVtYfXk+gOZCL6RcZ13Mc/Vr2U4hLiacwF49gtVpZd2gdQZYgLqVf\nIsAvgL4t+1K6VGmjSxNxCwpzcWtWq5W1B9cSZAniSsYVAvwCeK7lcwpxkTwU5uKWrFYr/zv4P4Is\nQaRmphLgF8CzLZ5ViIvcgMJc3MK1kZvlfKwMmfAdU+KDSM9KJ8AvgD4t+ijERQqgroniFvxMViJP\nfwt+QVSqmsn8IQE80/wZhbiUOOqaKB7JarXy9YGv2dEpGC5m0/h4AJsnPU3VKgpxkaLQnbkYItua\nzdcJXxMcGQzAv30DWBP2FHNml9bzMqVE02PjxCNkW7NZk7CGYEswpUuVJsAvgKeaPXXtAhYp8dTM\nIm4t25rN6v2rCY4MpkzpMgQ/EEzvpr0V4iJOojAXl8q2ZrNq/yqCLcGUvaUsEx+cyBP3PKEQF3Ey\nhbm4RLY1m5X7VhIcGcztZW4n9KFQHr/ncYW4iIsozMWpsq3ZrNi3gmBLMOXLlifs4TAea/KYQlzE\nxRTm4hRZ2Vm2EI8MpmLZioQ/Ek6vJr0U4iLFRGEuDhnun0VM8nJ+axRMy7srMeUfU3i08aMKcZFi\npjAXu2RlZ7Fs7zKWVA7mSnZlWBFBg/aP0GuEQlzECOpnLkWSlZ3F0r1LGR85nqrlqpLxQyBblj6M\nr28pNmxAA35EHKR+5uJSWdlZfLXnK8ZHjqe6T3WmPTaNh+5+iJRnS+GfDbNnK8hFjGTvnXkz4Ktc\nPzcCxgEf51qnO3MvkJmdyZLdS5gQNYEa5WsQ6BfIg3c/qDZxERcxcjh/aeAE0Ak4lmu9wtyDZWZn\nsnj3YiZETqBWhVoEmgJ5oOEDCnERFzOymeVh4DB/DXLxUJnZmXy560smRE2gTsU6zHpyFqaGJoW4\niJtzRpgPBBY7YT9ioMzsTBbtWsSEyAnUvaMuc3rPwdTQZHRZIlJIjoZ5WaA38F5+LwYGBl5fNplM\nmEwmBw8nzpaRlcGiXYuYGDWRepXqMfepuQpxkWJkNpsxm80O78fR985PAyOBXvm8pjZzN5aRlcEX\nu75gYtREGlRqQIBfAH4N/YwuS6TEM6rN/HlgiYP7kGKUkZXBwp0LmRg1kbTTjbhz3wJuz+hJ26eN\nrkxEHOHIs7nKY/vwc5WTahEXSs9KZ+62uTSd3pSv9n7Fwj4LuWfTj+z8pifr1tkeqCwinsuRO/PL\nQHVnFSKukZ6Vzmc7PiMkKoSm1ZqyqM8iutXvBoCPj20bX1/boB8R8Vwazu+l0rPSWbB9AaHRoTSr\n3owAvwC61uv6l22Sk2135Bq9KeI+9AxQASAtM40FO2wh3qJ6CwL8AuhSr4vRZYlIIWlulhLE3x8S\nE23NJIsX2+6q0zLTmL99PqHRodxb416W9l1K57qdjS5VRIqJwtwDJSaCxWJbfnlEGg/9ex6h0aG0\nqdmGFf1X0OmuTsYWKCLFTmHugXx8gDKp1H9mLrGdwkg72JaV/VcqxEVKMIW5h0nNTMX07hzM7cNo\n0bQdEx5ejW8dX6PLEhGDKcw9xNWMq8zZNoewjWF0qN2ByFFrFOIicp3C3M1dzbjK7K2z+SDmA3zr\n+PLNwG/oUKeD0WWJiJtRmLupqxlXmbV1Fh9s/IBOd3Xi2+e/pX3t9kaXJSJuSmFezPLrVpjblYwr\nzIqfRXhMOJ3rdmbtoLXcV+s+Y4oVEY+hMC9mubsV+vvDsmW25SsZV5gZP5PwmHC61uvKukHraFur\nrXGFiohHUZgXs7zzoVxOv8zM+JlM3jSZbvW6sf6F9bSp2cbYIkXE42g4fzG7Nh/K1E8us+Tgp0yO\nmUyPBj0Y13OcQlxENJzfU9zqc5mOb82gw+dT6NmgJxsGb6B1zdZGlyUiHk5hXkwupV/ik82f8GHs\nh5gamvhxyI/cW+Neo8sSES+hMHexi2kX+WTLJ0yNncoDDR/gpyE/0apGK6PLEhEvozB3kYtpF5m+\neTpTY6fyUKOH+PnFn2l5Z0ujyxIRL6Uwd7ILaReYvnk6EbERPNL4ESwvWWhxZwujyxIRL6cwd5IL\naReYFjeNiLgIHm38KJFDI2levbnRZYlICeFImFcG5gKtACswDIh1RlGeJCU1hY/jPubjzR/Tq0kv\noodG06x6M6PLEpESxpEw/whYC/TN2U95p1TkIVJSU/go7iOmbZ7GY00eY+OwjTSt1tToskSkhLI3\nzCsBPYAXc37OBFKcUpGbS05N5qPYj5i+ZTqP3/M4McNiuKfaPUaXJSIlnL1hfjfwO7AAaAtsBd4C\nrjipLreTnJpMRGwE0zdPp3ez3mx6eRNNqjYxuiwREcD+MC8DtAdeB7YAEcBo4L+5NwoMDLy+bDKZ\nMJlMdh7OOElXk4iIjeCTLZ/Qu1lv4obH0bhqY6PLEhEvYTabMZvNDu/H3rlZagGbsN2hA3THFuZP\n5trGo+dmOX/1PBGxEczYMoOnmz3N+z3eV4iLiMsV99wsp4FjQFMgEXgY2GvnvtzK+avnmbppKjPi\nZ9CneR82v7KZRlUaFTgPuYiIkRzpzfIG8CVQFjgMDHVKRQb548ofTI2dyqfxn/Js82eJfyWeu6vc\nff31G81DLiLiDhwJ851AR2cVYpRzV87x4aYPmbV1Fs+1eI6t/ltpWLnh37bLOw+5iIg7KbHzmZ+7\nco4pMVOYvW02fVv0ZUyPMfmG+DXX5iGfPVtNLCLiOva2mZe4MP/98u9M2TSFOdvm0K9lP8Z0H0OD\nyg2MLktEBNDDKQr0++XfmRwzmbnb59K/ZX+2j9hO/Ur1jS5LRMQpvD7Mz14+y+SYyczbPo8BrQYo\nxEXEK3ltmJ+9fJbwjeHM3zGfga0GsmPEDupVqmd0WSIiLuF1YX7m0hnCY8KZv30+g1oPYuerO6l7\nR12jyxIRcSmvCfPTl04TvjGcBTsW8EKbF9g9cjd33XGXBvuISIng8WF+6uIpPtj4AZ/v/JzBbQaz\nZ9Qe6lSsc/11DfYRkZLAY8P81MVThG0MY+HOhQxpO+RvIX6NBvuISElQ2ugCiurkxZO8te4tWs1o\nRSlKsXfUXiJ6ReQb5GBrWunXDzZsUBOLiHgvjxk0dOLCCcI2hrFo1yKG3jeUd7q9Q60KtZy2fxER\nd+C1g4ZOXDjBpOhJfLn7S4a1G8b+1/ZTs0JNo8sSEXErbhvmxy8c59Hxk0i8bQn1fh9G7H/30/Qu\nhbiISH7cLsyPpRwjNDqUpXuX4nP+ZTKX7ueXyzUYm6SeKCIiN+I2H4D+lvIbI78byX2z7qNi2Yok\nvJZA61MfwOUa6okiIlIAwz8A/TX5V0KjQ1m+bzmvtH+Ft7u8zZ3l7wQ07ayIlDweNwXur8m/EhIV\nwor9K/Bv78/bXd+muk91F5YjIuL+PKY3y9Hko4REhbBy/0pGdBjBgdcPKMRFRBzkSJgfBS4AWUAG\n0OlmG/+S9AshUSGsSljFqx1eJfH1RKr5VHPg8CIico0jYW4FTMD5m210JOkIIVEhrE5YzSjfURx8\n4yBVy1V14LAiIpKXo80sN23Xefnrl1lzYA2vdXxNIS4i4kKO3pn/iK2ZZRYwJ+8Gde+oy6E3DlGl\nXBUHDiMiIgVxpJ95N6Ad8BjwGtAj7wZbwoMolaYgFxFxNUfuzE/lfP8dWI3tA9Co3BusWxdIt262\nWQtNJhMmk8mBw4mIeB+z2YzZbHZ4P/b2M/cBbgEuAuWBH4CgnO/XWH19rZp6VkSkCIp70NDd2O7G\nwXZ3/yUQmmcba1KSVUEuIlIEHjcCVERE/s7eMHebibZERMR+CnMRES+gMBcR8QIKcxERL6AwFxHx\nAgpzEREvoDAXEfECCnMRES+gMBcR8QIKcxERL6AwFxHxAgpzEREvoDAXEfECCnMRES+gMBcR8QIK\ncxERL6AwFxHxAgpzEREvoDAXEfECjob5LcB24Fsn1CIiInZyNMzfAvYBenKzi5nNZqNL8Bo6l86l\n8+keHAnzusDjwFzseJK0FI3+wziPzqVz6Xy6B0fCfCrwDpDtpFpERMRO9ob5k8BZbO3luisXETGY\nvUEcAgwGMoHbgTuAlcCQXNscAho7VJ2ISMlzGGhixIH9UG8WERFDOaufuXqziIiIiIgYaT5wBth9\nk20+Bg4CO4F2xVGUByvofJqAFGwfPG8HxhZPWR6pHvAzsBfYA7x5g+10fRZOYc6nCV2fhXU7EAfs\nwDZWJ/QG2xXb9dkj5wA3Cp/HgbU5y/cDsa4sxgsUdD5NwDfFVo1nqwXcl7NcATgAtMizja7PwivM\n+TSh67MofHK+l8F27XXP83qRrk9H28yjgKSbvP4U8HnOchxQGajp4DG9WUHnE9QVtLBOY7vrAbgE\n7Afq5NlG12fhFeZ8gq7PoriS870stqlRzud5vUjXp6sn2roLOJbr5+PYRo6KfaxAV2xvudYCLY0t\nx2M0xPaOJy7Pel2f9mlI/udT12fRlMb2B/IMtiasfXleL9L1WcbZ1eUj719q9Xyx3zZsbZdXgMeA\nNUBTQytyfxWAFdjmEbqUz+u6PovmZudT12fRZGNruqoErMfWTGXOs02hr09X35mfwPaPe03dnHVi\nn4v8+dZsHXArUNW4ctzerdgGsy3CFix56fosmoLOp65P+6QA/wN886wv0vXp6jD/hj9HhXYGkrG9\npRD71OTPv9SdcpbztrOJTSlgHra3rhE32EbXZ+EV5nzq+iy86tjawAHKAY9g6wGUW7Fen0uAk0A6\ntradYcCInK9rpmMb2r8TaO+qQrxEQefzNWzdwnYAMdj+gSV/3bG9jd3Bn13lHkPXp70Kcz51fRZe\na2zNUjuAXdgmLQRdnyIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiIiJyzf8Hr6QvfAFzJdwAAAAASUVO\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1089a37d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(xs,ys, '.')\n",
    "\n",
    "\n",
    "# def padAll(xs):\n",
    "#     tmp = np.zeros((xs.size, 2))\n",
    "#     tmp[:, 0] = 1.\n",
    "#     tmp[:, 1] = xs\n",
    "#     return tmp\n",
    "\n",
    "def padAll(xs):\n",
    "    tmp = np.zeros((xs.size, 2))\n",
    "    for i in xrange(xs.size):\n",
    "        tmp[i, 0] = 1.\n",
    "        tmp[i, 1] = xs[i]\n",
    "    return tmp\n",
    "\n",
    "pxs = padAll(xs)\n",
    "\n",
    "# def cost(ws):\n",
    "#     guesses = np.dot(pxs, ws)\n",
    "#     return np.sum((ys - guesses)**2)\n",
    "\n",
    "def cost(ws):\n",
    "    tmp = 0\n",
    "    for i in xrange(xs.size):\n",
    "        guess = (ws[0] * pxs[i][0]) + (ws[1] * pxs[i][1])\n",
    "        tmp += (ys[i] - guess)**2\n",
    "    return tmp\n",
    "\n",
    "\n",
    "import scipy.optimize as opt\n",
    "res = opt.fmin(cost, [0.,1.])  \n",
    "print res\n",
    "guesses = np.dot(pxs, res)\n",
    "plt.plot(xs, guesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "6) Why stop at one dimension. Here you are given a data set of house price(in million) given area, bed room and bath room. Find it in house price.csv.\n",
    "\n",
    "Find the price for 45m^2 house with 2 bedroom and 2 bathroom.\n",
    "\n",
    "Hint: `np.from_text` and use numpy array slicing will save you a lot of typing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.928485\n",
      "         Iterations: 283\n",
      "         Function evaluations: 478\n",
      "[ 0.3998773   0.10027504  0.30784073  0.12015975]\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt('house_price.csv', delimiter=',')\n",
    "prices = data[:, 0]\n",
    "features = data[:, 1:]\n",
    "\n",
    "def padAll(ftr):\n",
    "    row, col = ftr.shape\n",
    "    tmp = np.zeros((row, col + 1))\n",
    "    tmp[:, 0] = 1.\n",
    "    tmp[:, 1:] = ftr\n",
    "    return tmp\n",
    "\n",
    "#print padAll(features)\n",
    "\n",
    "padftr = padAll(features)\n",
    "#print padftr\n",
    "\n",
    "def cost(ws):\n",
    "    guesses = np.dot(padftr, ws)\n",
    "    return np.sum((prices - guesses)**2)\n",
    "\n",
    "\n",
    "import scipy.optimize as opt\n",
    "res = opt.fmin(cost, [1.,1.,1.,1.])  \n",
    "print res\n",
    "\n",
    "# plt.plot(guesses, prices, '.')\n",
    "\n",
    "# def cost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ROC curve first? May be...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1) Why is linear regression not suitable for predicting probabilities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Consider logistic function\n",
    "\n",
    "$$\\theta(s) = \\frac{1}{1+e^{-s}}$$\n",
    "\n",
    "Find $f(\\infty)$ and $f(-\\infty)$ and just plot the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Show that $$\\theta(-s) = 1 - \\theta(s)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Combine logistic function and linear regression to make function that takes in a bunch of features and give out a probability. What parameters parametrize your models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Given that you use hypothesis $$ P_\\vec{w}(1 | \\vec{x}) = \\theta(\\vec{w}\\cdot\\vec{x}) $$\n",
    "and that you only 2 classes (+1 and -1) what is\n",
    "\n",
    "$$ P_\\vec{w}(-1 | \\vec{x})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Use the fact from 3) write what you found in 5 in a simpler form\n",
    "\n",
    "$$\n",
    "P_\\vec{w}(y|\\vec{x}) = \\begin{cases}\n",
    "    \\ldots & y = 1 \\\\\n",
    "    \\ldots & y = -1\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Using the fact that $y\\in\\{-1, 1\\}$Convince yourself that what you wrote above is just\n",
    "\n",
    "$$ P_\\vec{w}\\left(y|\\vec{x} \\right) = \\theta\\left(y \\times \\left( \\vec{w} \\cdot \\vec{x} \\right) \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) How do we distinguish a good hypothesis from bad hypothesis? (good $\\vec{w}$ from bad $\\vec{w}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) What does likelihood represents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) Let us do one concrete example here.  Calculate the likelihood for $\\vec{w}$ given these data point\n",
    "$$\\vec{w}_1 = (0,1,2)$$\n",
    "- $y = 1$, $x=[1, -1]$\n",
    "- $y = -1$, $x=[-2, 1]$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11) Is $\\vec{w}_2 = (1,1,1)$ a better hypothesis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12) What happend when we take log of the likelihood?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13) Write down our cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14) What is the parameter that we are trying to adjust?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15) Look at gold_target data file and build a system to decide whether we should dig the gold or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
